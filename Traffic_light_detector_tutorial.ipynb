{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_light_detector_tutorial",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMJ1BNxX08pd",
        "outputId": "cf634ed3-f82a-459f-cc6a-23e776d14f31"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFFkh0ea0-u4",
        "outputId": "3b817493-6f6f-4ab2-9f01-71a869a40600"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.22)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-dvbxln54\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-dvbxln54\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.22)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263919 sha256=bf619ef5d4e5c74291375aff7d8ecdc18c53d58085268a3d66ee5167e0f9cfea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i420guho/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2wBpv6H1Q72",
        "outputId": "4c617091-9aaa-447d-d6b1-d6c0a5590757"
      },
      "source": [
        "!git clone https://github.com/aapanaetov/Traffic_Light_Detection.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Traffic_Light_Detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txlc6ysfEiS2",
        "outputId": "c242c344-27d7-421c-ff6c-4b2f780c4671"
      },
      "source": [
        "os.listdir('drive/MyDrive/Detection/weights')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['res50FPN_final.pth', 'mobilenet_v3_final.pth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlyYMwKe2MUv"
      },
      "source": [
        "import sys\n",
        "sys.path.append('Traffic_Light_Detection/')\n",
        "import utils\n",
        "from model import get_model\n",
        "from dataset import BoschDataset, LisaDataset\n",
        "from dataset import get_transform, label_to_class\n",
        "from engine import train_one_epoch, evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8gpFkFh2cfH",
        "outputId": "aa305933-580d-4fdc-b9f5-279d1924e372"
      },
      "source": [
        "# Choose the model to test\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "model = get_model('mobilenet_v3_FPN').to(device)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/Detection/weights/mobilenet_v3_final.pth'))\n",
        "\n",
        "# model = get_model('res50_FPN').to(device)\n",
        "# model.load_state_dict(torch.load('drive/MyDrive/Detection/weights/res50FPN_final.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lutgZ9Rl3alE"
      },
      "source": [
        "# Change paths to save json results and video visualization somewhere else if you want\n",
        "\n",
        "def make_prediction(video_path, model, save_video=False):\n",
        "    video_name = video_path[video_path.rfind('/')+1:-4]\n",
        "    save_result_path = 'drive/MyDrive/{}.json'.format(video_name)\n",
        "    if save_video:\n",
        "        save_video_path = 'drive/MyDrive/{}.mp4'.format(video_name)\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model.eval()\n",
        "    \n",
        "    frame_array = []\n",
        "    result_video = {}\n",
        "    count = 0\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    \n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if success:\n",
        "            height, width, _ = image.shape\n",
        "            size = (width, height)\n",
        "            result_frame = {}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if image.max() < 2:\n",
        "                    print('WRONG NORMALIZATION')\n",
        "                    break\n",
        "                prediction = model([torch.from_numpy((image / 255.).transpose((2,0,1))).type(torch.FloatTensor).to(device)])[0]\n",
        "            \n",
        "            n_pred = len(prediction['scores'].cpu().detach().numpy())\n",
        "            traffic_light = 0\n",
        "            for i in range(n_pred):\n",
        "                if prediction['scores'][i].cpu().detach().numpy() > 0.5:\n",
        "                    bbox = prediction['boxes'][i].cpu().detach().numpy().astype(np.uint16)\n",
        "                    label = label_to_class(int(prediction['labels'][i].cpu().detach().numpy()))\n",
        "                    \n",
        "                    traffic_light_dict = {}\n",
        "                    traffic_light_dict['coords'] = bbox.tolist()\n",
        "                    traffic_light_dict['state'] = label\n",
        "                    traffic_light_dict['affect'] = True\n",
        "                    result_frame['traffic_light_{}'.format(traffic_light)] = traffic_light_dict\n",
        "                    traffic_light += 1\n",
        "                    \n",
        "                    if save_video:\n",
        "                        image = cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (36,255,12), 2)\n",
        "                        image = cv2.putText(image, label, (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "                        \n",
        "            result_video[str(count)] = result_frame\n",
        "            count += 1\n",
        "            \n",
        "            if save_video:\n",
        "                frame_array.append(image)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(save_result_path, 'w') as f:\n",
        "        json.dump(result_video, f)\n",
        "                \n",
        "    if save_video:\n",
        "        out = cv2.VideoWriter(save_video_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "        for i in range(len(frame_array)):\n",
        "            out.write(frame_array[i])\n",
        "        out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RDI-3R30p1"
      },
      "source": [
        "# Use the following two lines to predict results for all videous in test_videos folder\n",
        "\n",
        "# for video_path in os.listdir('drive/MyDrive/Detection/test_videos'):\n",
        "#     make_prediction(video_path='drive/MyDrive/Detection/test_videos/'+video_path, model=model, save_video=True)\n",
        "\n",
        "make_prediction(video_path='drive/MyDrive/Detection/test_videos/video_0.mp4', model=model, save_video=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPvQvpEH25di"
      },
      "source": [
        "# The following two cells just to test inference time \n",
        "# You can download any other image instead so u don't have to download the whole Bosch Dataset\n",
        "\n",
        "# ds = BoschDataset(get_transform(train=True))\n",
        "# sample = ds.samples[0]\n",
        "# image = plt.imread(sample['path'])\n",
        "image = np.zeros((800, 1200, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwByZKUp2_Tf",
        "outputId": "6b8b5f51-4e01-49ac-e46d-02295f5b4ea5"
      },
      "source": [
        "%%time\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model.eval()\n",
        "\n",
        "for i in range(100):\n",
        "    with torch.no_grad():\n",
        "        prediction = model([torch.from_numpy(image.transpose((2,0,1))).type(torch.FloatTensor).to(device)])[0]\n",
        "\n",
        "# So we have almost 37 FPS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.34 s, sys: 403 ms, total: 2.74 s\n",
            "Wall time: 2.74 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UajIQRwL4dyo"
      },
      "source": [
        "# The cells below show how to set up training\n",
        "# You should download datasets to be ablo to run this code\n",
        "\n",
        "Bosch_train = BoschDataset(get_transform(train=True))\n",
        "Lisa_train = LisaDataset(get_transform(train=True))\n",
        "Bosch_test = BoschDataset(get_transform(train=False))\n",
        "Lisa_test = LisaDataset(get_transform(train=False))\n",
        "\n",
        "dataset = torch.utils.data.ConcatDataset([Bosch_train, Lisa_train])\n",
        "dataset_test = torch.utils.data.ConcatDataset([Bosch_test, Lisa_test])\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=8, shuffle=True, collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=1, shuffle=False, collate_fn=utils.collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xbda5l9462g"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "model = get_model('mobilenet_v3_FPN').to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPsWESAY46w9"
      },
      "source": [
        "num_epochs = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "  torch.save(model.state_dict(), 'weights/mobilenet_v3_4e_Bosch_Lisa.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}